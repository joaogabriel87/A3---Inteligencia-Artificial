{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaogabriel87/A3---Inteligencia-Artificial/blob/main/AED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6w1avjO50QQ7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar e padronizar as colunas\n",
        "anos = range(2015, 2025)\n",
        "dfs = []"
      ],
      "metadata": {
        "id": "uw0NcVgc089z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ano in anos:\n",
        "    try:\n",
        "        df = pd.read_csv(f\"acidentes_{ano}.csv\", sep=\";\", encoding='utf-8')  # Carregar arquivo\n",
        "        df.rename(columns={\"data\": \"Data\"}, inplace=True)  # Padronizar nomes de colunas\n",
        "        df[\"Ano\"] = ano  # Adicionar coluna de ano\n",
        "        dfs.append(df)\n",
        "        print(f\"Successfully loaded data for year {ano}\")  # Mensagem de confirmação\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file for year {ano}: {e}\")\n",
        "\n",
        "        # Verificar quantidade de DataFrames carregados\n",
        "print(f\"Total DataFrames loaded: {len(dfs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-fRoMSC91DCP",
        "outputId": "22f62be6-2b91-49fe-d4b9-f7a74b084b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error reading file for year 2015: [Errno 2] No such file or directory: 'acidentes_2015.csv'\n",
            "Error reading file for year 2016: [Errno 2] No such file or directory: 'acidentes_2016.csv'\n",
            "Error reading file for year 2017: [Errno 2] No such file or directory: 'acidentes_2017.csv'\n",
            "Error reading file for year 2018: [Errno 2] No such file or directory: 'acidentes_2018.csv'\n",
            "Error reading file for year 2019: [Errno 2] No such file or directory: 'acidentes_2019.csv'\n",
            "Error reading file for year 2020: [Errno 2] No such file or directory: 'acidentes_2020.csv'\n",
            "Error reading file for year 2021: [Errno 2] No such file or directory: 'acidentes_2021.csv'\n",
            "Error reading file for year 2022: [Errno 2] No such file or directory: 'acidentes_2022.csv'\n",
            "Error reading file for year 2023: [Errno 2] No such file or directory: 'acidentes_2023.csv'\n",
            "Error reading file for year 2024: [Errno 2] No such file or directory: 'acidentes_2024.csv'\n",
            "Total DataFrames loaded: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenar todos os DataFrames\n",
        "df_principal = pd.concat(dfs, ignore_index=True)\n",
        "print(\"Anos disponíveis:\", df_principal['Ano'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "54_4d7h01-1v",
        "outputId": "1a22a662-47b4-4ad1-dba0-aa565bc478c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No objects to concatenate",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a858772ac078>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Concatenar todos os DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_principal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anos disponíveis:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_principal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ano'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_keys_and_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;31m# figure out what our result ndim is going to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padronizar datas no formato ISO para 2018 e 2019\n",
        "df_2018_2019 = df_principal[(df_principal['Ano'] == 2018) | (df_principal['Ano'] == 2019)]\n",
        "df_2018_2019['Data'] = pd.to_datetime(df_2018_2019['Data'], format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
        "df_principal.loc[df_2018_2019.index, 'Data'] = df_2018_2019['Data']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t85LshVHgZr5",
        "outputId": "bf3f4656-81ca-442c-e0d2-1a133dbe4b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-3adda5d133cf>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_2018_2019['Data'] = pd.to_datetime(df_2018_2019['Data'], format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter a coluna 'vitimas' para numérico, substituindo valores inválidos por 0\n",
        "df_principal['vitimas'] = pd.to_numeric(df_principal['vitimas'], errors='coerce')\n",
        "\n",
        "# Aplicar a transformação para definir 1 se >= 1, caso contrário 0\n",
        "df_principal['vitimas'] = df_principal['vitimas'].apply(lambda x: 1 if x >= 1 else 0)"
      ],
      "metadata": {
        "id": "naLSNz74Ozhf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deixar a coluna \"Tipo\" com os mesmo valores da coluna de \"Vitimas\"\n",
        "df_principal[\"tipo\"] = df_principal[\"vitimas\"]\n"
      ],
      "metadata": {
        "id": "_R09O6RASLNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Substituir valores nulos restantes por uma string padrão ou outro valor\n",
        "df_principal.fillna(\"null\", inplace=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Q08QVsihPrTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar as primeiras linhas dos dados processados\n",
        "print(df_principal.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaHQIHoW0A0_",
        "outputId": "a8f6601d-d7bd-4608-e509-efbcfb639b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   tipo    situacao        Data          hora        bairro  \\\n",
            "0     0   CANCELADA  2015-12-03  11:36:00.000  CASA AMARELA   \n",
            "1     0  FINALIZADA  2015-06-01  06:35:00.000  ENCRUZILHADA   \n",
            "2     0  FINALIZADA  2015-06-01  08:04:00.000    BOA VIAGEM   \n",
            "3     0  FINALIZADA  2015-06-01  08:06:00.000      AFOGADOS   \n",
            "4     0   CANCELADA  2015-06-01  08:13:00.000      MADALENA   \n",
            "\n",
            "                      endereco numero                        complemento  \\\n",
            "0                     AV NORTE   null     SENTIDO SUBURBIO   E/F AO SESC   \n",
            "1                 EST DE BELEM   null   IGREJA BATISTA MEMORIAL DE BELÉM   \n",
            "2  RUA ERNESTO DE PAULA SANTOS   null                     SEMAFORO Nº217   \n",
            "3                       AV SUL   null    AO LADO DA ESTAÇAO LARGO DA PAZ   \n",
            "4                  RUA BENFICA   null  EM  FRENTE AO CLUBE INTERNACIONAL   \n",
            "\n",
            "  natureza                     descricao  ... condicao_via conservacao_via  \\\n",
            "0  COLISÃO           COLISÃO SEM VITIMAS  ...         null            null   \n",
            "1  COLISÃO                  SEM VÍTIMAS.  ...         null            null   \n",
            "2  COLISÃO                    SEM VITIMA  ...         null            null   \n",
            "3  COLISÃO                   COLISAO S/V  ...         null            null   \n",
            "4  COLISÃO  GM RIBEIRO JA NO LOCAL VT 05  ...         null            null   \n",
            "\n",
            "  ponto_controle situacao_placa velocidade_max_via mao_direcao divisao_via1  \\\n",
            "0           null           null               null        null         null   \n",
            "1           null           null               null        null         null   \n",
            "2           null           null               null        null         null   \n",
            "3           null           null               null        null         null   \n",
            "4           null           null               null        null         null   \n",
            "\n",
            "  divisao_via2 divisao_via3  Protocolo  \n",
            "0         null         null       null  \n",
            "1         null         null       null  \n",
            "2         null         null       null  \n",
            "3         null         null       null  \n",
            "4         null         null       null  \n",
            "\n",
            "[5 rows x 44 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o DataFrame processado em um novo arquivo CSV\n",
        "df_principal.to_csv(\"acidentes_2015_2024.csv\", index=False)"
      ],
      "metadata": {
        "id": "a_usWBRJQOyV",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}